{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the path\n",
    "BASE_PATH = r\"C:\\Users\\NyashaKampila\\Desktop\\Projects\\Purchase-Order-Creation-Project\"\n",
    "INPUT_FILE = os.path.join(BASE_PATH, \"PO Data.csv\")\n",
    "OUTPUT_FILE = os.path.join(BASE_PATH, \"PO Data_formatted.xlsx\")\n",
    "\n",
    "def clean_and_format_data(input_file, output_file):\n",
    "    # Read the CSV file\n",
    "    print(f\"Reading CSV file from: {input_file}\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Count initial rows\n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Clean and format the data\n",
    "    print(\"Cleaning and formatting data...\")\n",
    "    \n",
    "    # 1. Format dates\n",
    "    date_columns = ['BillDate', 'DueDate']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # 2. Format currency amounts\n",
    "    currency_columns = ['SubTotal', 'Total', 'Balance', 'Rate', 'ItemTotal']\n",
    "    for col in currency_columns:\n",
    "        df[col] = df[col].round(2)\n",
    "        df[col] = df[col].apply(lambda x: f\"{x:,.2f}\")\n",
    "    \n",
    "    # 3. Clean up descriptions\n",
    "    df['Description'] = df['Description'].replace('No Description', '')\n",
    "    \n",
    "    # 4. Remove duplicate rows\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    # 5. Sort the data by date and bill number\n",
    "    df_cleaned = df_cleaned.sort_values(['BillDate', 'BillNumber'])\n",
    "    \n",
    "    # 6. Reorganize columns for better readability\n",
    "    columns_order = [\n",
    "        'BillNumber',\n",
    "        'BillDate',\n",
    "        'DueDate',\n",
    "        'CustomerName',\n",
    "        'VendorName',\n",
    "        'SKU',\n",
    "        'ItemName',\n",
    "        'Description',\n",
    "        'Quantity',\n",
    "        'Unit',\n",
    "        'Rate',\n",
    "        'ItemTotal',\n",
    "        'SubTotal',\n",
    "        'Total',\n",
    "        'Balance',\n",
    "        'CurrencySymbol',\n",
    "        'PaymentTerms',\n",
    "        'Source',\n",
    "        'CreatedTime'\n",
    "    ]\n",
    "    \n",
    "    # Only include columns that exist in the dataframe\n",
    "    columns_order = [col for col in columns_order if col in df_cleaned.columns]\n",
    "    df_cleaned = df_cleaned[columns_order]\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary = {\n",
    "        'Total Orders': df_cleaned['BillNumber'].nunique(),\n",
    "        'Total Customers': df_cleaned['CustomerName'].nunique(),\n",
    "        'Total Items': df_cleaned['SKU'].nunique(),\n",
    "        'Date Range': f\"{df_cleaned['BillDate'].min()} to {df_cleaned['BillDate'].max()}\",\n",
    "        'Total Records': len(df_cleaned),\n",
    "        'Duplicates Removed': initial_count - len(df_cleaned)\n",
    "    }\n",
    "    \n",
    "    # Create a pivot table for customer analysis\n",
    "    customer_summary = pd.pivot_table(\n",
    "        df_cleaned,\n",
    "        index='CustomerName',\n",
    "        values=['BillNumber', 'ItemTotal'],\n",
    "        aggfunc={\n",
    "            'BillNumber': 'nunique',\n",
    "            'ItemTotal': lambda x: sum(float(str(i).replace(',', '')) for i in x)\n",
    "        }\n",
    "    ).round(2)\n",
    "    \n",
    "    customer_summary.columns = ['Total Orders', 'Total Amount']\n",
    "    customer_summary = customer_summary.sort_values('Total Amount', ascending=False)\n",
    "    \n",
    "    # Save cleaned data to Excel file with formatting\n",
    "    print(f\"Saving formatted data to: {output_file}\")\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        # Write main data\n",
    "        df_cleaned.to_excel(writer, sheet_name='Orders', index=False)\n",
    "        \n",
    "        # Write summary\n",
    "        pd.DataFrame([summary]).transpose().to_excel(writer, sheet_name='Summary')\n",
    "        \n",
    "        # Write customer summary\n",
    "        customer_summary.to_excel(writer, sheet_name='Customer Analysis')\n",
    "        \n",
    "        # Get workbook and worksheet objects\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Orders']\n",
    "        \n",
    "        # Add formats\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'text_wrap': True,\n",
    "            'valign': 'top',\n",
    "            'bg_color': '#D3D3D3',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        # Format the header row\n",
    "        for col_num, value in enumerate(df_cleaned.columns.values):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "            \n",
    "        # Auto-adjust columns' width\n",
    "        for idx, col in enumerate(df_cleaned.columns):\n",
    "            series = df_cleaned[col]\n",
    "            max_len = max(\n",
    "                series.astype(str).apply(len).max(),\n",
    "                len(str(series.name))\n",
    "            ) + 1\n",
    "            worksheet.set_column(idx, idx, max_len)\n",
    "\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Ensure the path exists\n",
    "        if not os.path.exists(INPUT_FILE):\n",
    "            raise FileNotFoundError(f\"Input file not found at: {INPUT_FILE}\")\n",
    "        \n",
    "        summary = clean_and_format_data(INPUT_FILE, OUTPUT_FILE)\n",
    "        \n",
    "        print(\"\\nData Processing Summary:\")\n",
    "        print(\"------------------------\")\n",
    "        for key, value in summary.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(f\"\\nFormatted data has been saved to: {OUTPUT_FILE}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file from: C:\\Users\\NyashaKampila\\Desktop\\Projects\\Purchase-Order-Creation-Project\\PO Data.csv\n",
      "Cleaning and formatting data...\n",
      "Generating Vendor IDs...\n",
      "Generating Customer IDs...\n",
      "\n",
      "Vendor ID Mappings:\n",
      "Farmers Den Pack House Ltd: FAR559\n",
      "Foodies Enterprise Zambia Ltd: FOO094\n",
      "R & R Meats: RRM219\n",
      "Uniturtle Farm: UNI510\n",
      "Yalelo Zambia: YAL421\n",
      "Abo Abbas Supermarket: ABO973\n",
      "Nawa Nawa Farm: NAW566\n",
      "Hrvst Emporium LTD: HRV168\n",
      "Sea Pride: SEA345\n",
      "Connicks Farms: CON471\n",
      "\n",
      "Customer ID Mappings:\n",
      "Cozy Zambia: COZ135\n",
      "Freshbake Waddington: FRE211\n",
      "Newrest: NEW117\n",
      "Prime Joint Zambia: PRI627\n",
      "Mocha n Chai: MOC317\n",
      "Vida e Caffe Pinnacle: VID619\n",
      "Controller Ciela Resort and Spa: CON442\n",
      "Fox N Hound Restaurant: FOX601\n",
      "Detohome Enterprise Limited: DET704\n",
      "Vida e Cafe Cosmo: VID921\n",
      "Vida E Cafe Zambezi: VID036\n",
      "Urban Yard: URB100\n",
      "Vida e Caffe East Park: VID474\n",
      "Camren Catering: CAM248\n",
      "Afridelivery: AFR953\n",
      "Flame: FLA930\n",
      "Copenhagen Yard Bar & Kitchen: COP982\n",
      "Quick Service Restaurants LTD: QUI941\n",
      "Millas Foods Zambia Limited: MIL519\n",
      "Just Chicken Ltd: JUS148\n",
      "Prime Venue: PRI668\n",
      "Urban Masaii: URB530\n",
      "TA Pie's Cafe: TAP454\n",
      "Seapride  Foods Zambia Limited: SEA854\n",
      "R & R Meats: RRM219\n",
      "Granddaddy's: GRA603\n",
      "ASF Zambia Hotel Holding T/A: ASF440\n",
      "Freshbake Ibex: FRE703\n",
      "Soho Lounge Bar & Bistro: SOH494\n",
      "Orchard Farm Stores T/A Aroma: ORC292\n",
      "LUSAKA LEGACY RESORT Protein: LUS706\n",
      "Musubi: MUS362\n",
      "Simply Asia Pinnacle: SIM322\n",
      "Saving formatted data to: C:\\Users\\NyashaKampila\\Desktop\\Projects\\Purchase-Order-Creation-Project\\PO Data_formatted.xlsx\n",
      "\n",
      "Data Processing Summary:\n",
      "------------------------\n",
      "Total Orders: 161\n",
      "Total Customers: 33\n",
      "Total Vendors: 10\n",
      "Date Range: 2024-12-20 to 2025-01-09\n",
      "Total Records: 999\n",
      "Duplicates Removed: 0\n",
      "\n",
      "Formatted data has been saved to: C:\\Users\\NyashaKampila\\Desktop\\Projects\\Purchase-Order-Creation-Project\\PO Data_formatted.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the path\n",
    "BASE_PATH = r\"C:\\Users\\NyashaKampila\\Desktop\\Projects\\Purchase-Order-Creation-Project\"\n",
    "INPUT_FILE = os.path.join(BASE_PATH, \"PO Data.csv\")\n",
    "OUTPUT_FILE = os.path.join(BASE_PATH, \"PO Data_formatted.xlsx\")\n",
    "\n",
    "def generate_vendor_id(vendor_name: str) -> str:\n",
    "    \"\"\"Generate a vendor ID based on vendor name\"\"\"\n",
    "    # Remove special characters and spaces, take first 3 letters\n",
    "    prefix = ''.join(c for c in vendor_name if c.isalnum())[:3].upper()\n",
    "    # Add a unique number (using hash of full name to ensure consistency)\n",
    "    hash_num = abs(hash(vendor_name)) % 1000\n",
    "    return f\"{prefix}{hash_num:03d}\"\n",
    "\n",
    "def generate_customer_id(customer_name: str) -> str:\n",
    "    \"\"\"Generate a customer ID based on customer name\"\"\"\n",
    "    # Remove special characters and spaces, take first 3 letters\n",
    "    prefix = ''.join(c for c in customer_name if c.isalnum())[:3].upper()\n",
    "    # Add a unique number (using hash of full name to ensure consistency)\n",
    "    hash_num = abs(hash(customer_name)) % 1000\n",
    "    return f\"{prefix}{hash_num:03d}\"\n",
    "\n",
    "def clean_and_format_data(input_file, output_file):\n",
    "    # Read the CSV file\n",
    "    print(f\"Reading CSV file from: {input_file}\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Count initial rows\n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Clean and format the data\n",
    "    print(\"Cleaning and formatting data...\")\n",
    "    \n",
    "    # Generate and add Vendor IDs\n",
    "    print(\"Generating Vendor IDs...\")\n",
    "    vendor_ids = {name: generate_vendor_id(name) for name in df['VendorName'].unique()}\n",
    "    df['VendorID'] = df['VendorName'].map(vendor_ids)\n",
    "    \n",
    "    # Generate and add Customer IDs\n",
    "    print(\"Generating Customer IDs...\")\n",
    "    customer_ids = {name: generate_customer_id(name) for name in df['CustomerName'].unique()}\n",
    "    df['CustomerID'] = df['CustomerName'].map(customer_ids)\n",
    "    \n",
    "    # Print the mappings for reference\n",
    "    print(\"\\nVendor ID Mappings:\")\n",
    "    for vendor, vid in vendor_ids.items():\n",
    "        print(f\"{vendor}: {vid}\")\n",
    "    \n",
    "    print(\"\\nCustomer ID Mappings:\")\n",
    "    for customer, cid in customer_ids.items():\n",
    "        print(f\"{customer}: {cid}\")\n",
    "    \n",
    "    # 1. Format dates\n",
    "    date_columns = ['BillDate', 'DueDate']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # 2. Format currency amounts\n",
    "    currency_columns = ['SubTotal', 'Total', 'Balance', 'Rate', 'ItemTotal']\n",
    "    for col in currency_columns:\n",
    "        df[col] = df[col].round(2)\n",
    "        df[col] = df[col].apply(lambda x: f\"{x:,.2f}\")\n",
    "    \n",
    "    # 3. Clean up descriptions\n",
    "    df['Description'] = df['Description'].replace('No Description', '')\n",
    "    \n",
    "    # 4. Remove duplicate rows\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    # 5. Sort the data by date and bill number\n",
    "    df_cleaned = df_cleaned.sort_values(['BillDate', 'BillNumber'])\n",
    "    \n",
    "    # 6. Reorganize columns for better readability\n",
    "    columns_order = [\n",
    "        'BillNumber',\n",
    "        'BillDate',\n",
    "        'DueDate',\n",
    "        'CustomerID',\n",
    "        'CustomerName',\n",
    "        'VendorID',\n",
    "        'VendorName',\n",
    "        'ItemName',\n",
    "        'Description',\n",
    "        'Quantity',\n",
    "        'Unit',\n",
    "        'Rate',\n",
    "        'ItemTotal',\n",
    "        'SubTotal',\n",
    "        'Total',\n",
    "        'Balance',\n",
    "        'CurrencySymbol',\n",
    "        'PaymentTerms',\n",
    "        'Source',\n",
    "        'CreatedTime'\n",
    "    ]\n",
    "    \n",
    "    # Only include columns that exist in the dataframe\n",
    "    columns_order = [col for col in columns_order if col in df_cleaned.columns]\n",
    "    df_cleaned = df_cleaned[columns_order]\n",
    "    \n",
    "    # Verify no NaN values in ID columns\n",
    "    if df_cleaned['VendorID'].isna().any() or df_cleaned['CustomerID'].isna().any():\n",
    "        print(\"Warning: Found NaN values in ID columns!\")\n",
    "        print(f\"NaN in VendorID: {df_cleaned['VendorID'].isna().sum()}\")\n",
    "        print(f\"NaN in CustomerID: {df_cleaned['CustomerID'].isna().sum()}\")\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary = {\n",
    "        'Total Orders': df_cleaned['BillNumber'].nunique(),\n",
    "        'Total Customers': df_cleaned['CustomerName'].nunique(),\n",
    "        'Total Vendors': df_cleaned['VendorName'].nunique(),\n",
    "        'Date Range': f\"{df_cleaned['BillDate'].min()} to {df_cleaned['BillDate'].max()}\",\n",
    "        'Total Records': len(df_cleaned),\n",
    "        'Duplicates Removed': initial_count - len(df_cleaned)\n",
    "    }\n",
    "    \n",
    "    # Create a pivot table for customer analysis\n",
    "    customer_summary = pd.pivot_table(\n",
    "        df_cleaned,\n",
    "        index=['CustomerID', 'CustomerName'],\n",
    "        values=['BillNumber', 'ItemTotal'],\n",
    "        aggfunc={\n",
    "            'BillNumber': 'nunique',\n",
    "            'ItemTotal': lambda x: sum(float(str(i).replace(',', '')) for i in x)\n",
    "        }\n",
    "    ).round(2)\n",
    "    \n",
    "    customer_summary.columns = ['Total Orders', 'Total Amount']\n",
    "    customer_summary = customer_summary.sort_values('Total Amount', ascending=False)\n",
    "    \n",
    "    # Save cleaned data to Excel file with formatting\n",
    "    print(f\"Saving formatted data to: {output_file}\")\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        # Write main data\n",
    "        df_cleaned.to_excel(writer, sheet_name='Orders', index=False)\n",
    "        \n",
    "        # Write summary\n",
    "        pd.DataFrame([summary]).transpose().to_excel(writer, sheet_name='Summary')\n",
    "        \n",
    "        # Write customer summary\n",
    "        customer_summary.to_excel(writer, sheet_name='Customer Analysis')\n",
    "        \n",
    "        # Get workbook and worksheet objects\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Orders']\n",
    "        \n",
    "        # Add formats\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'text_wrap': True,\n",
    "            'valign': 'top',\n",
    "            'bg_color': '#D3D3D3',\n",
    "            'border': 1\n",
    "        })\n",
    "        \n",
    "        # Format the header row\n",
    "        for col_num, value in enumerate(df_cleaned.columns.values):\n",
    "            worksheet.write(0, col_num, value, header_format)\n",
    "            \n",
    "        # Auto-adjust columns' width\n",
    "        for idx, col in enumerate(df_cleaned.columns):\n",
    "            series = df_cleaned[col]\n",
    "            max_len = max(\n",
    "                series.astype(str).apply(len).max(),\n",
    "                len(str(series.name))\n",
    "            ) + 1\n",
    "            worksheet.set_column(idx, idx, max_len)\n",
    "\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Ensure the path exists\n",
    "        if not os.path.exists(INPUT_FILE):\n",
    "            raise FileNotFoundError(f\"Input file not found at: {INPUT_FILE}\")\n",
    "        \n",
    "        summary = clean_and_format_data(INPUT_FILE, OUTPUT_FILE)\n",
    "        \n",
    "        print(\"\\nData Processing Summary:\")\n",
    "        print(\"------------------------\")\n",
    "        for key, value in summary.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(f\"\\nFormatted data has been saved to: {OUTPUT_FILE}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
